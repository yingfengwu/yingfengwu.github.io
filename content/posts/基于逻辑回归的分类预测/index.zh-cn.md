---
weight: 4
title: "基于逻辑回归的分类预测学习笔记"
date: 2021-06-01T17:57:40+08:00
lastmod: 2021-06-01T18:45:40+08:00
draft: false
author: "yingfengwu"
authorLink: "https://yingfengwu.github.io"
description: "这篇文章介绍了逻辑回归的分类预测."
resources:
- name: "featured-image"
  src: "featured-image.png"

tags: ["机器学习", "逻辑回归", "分类", “预测”]
categories: ["天池AI训练营"]

lightgallery: true
---

### 学习知识点概要

  * 逻辑回归的介绍及应用

  * 基于鸢尾花数据集的分类预测实战

### 学习内容

#### 逻辑回归的介绍

逻辑回归虽名为“回归”，但实际是一种分类学习方法。

* 逻辑回归（或称对数几率回归）突出的特点：模型简单和模型可解释性强
 * 优劣势：
   * 优点：实现简单，易于理解和实现；计算代价不高，速度很快，存储资源低；	
   * 缺点：容易欠拟合，分类精度可能不高；由于其本质上是一个线性的分类器，所以不能应对较为复杂的数据情况
* 对于多分类（有三个及以上输出）而言，将多个二分类的逻辑回归组合，即可实现多分类

逻辑回归原理:

通过Logistic函数（或称为Sigmoid函数），对多元线性回归方程中的变量值进行决策（分类预测）。

![sigmoid](sigmoid.png "sigmoid函数")

Logistic函数(本文简写为logi(z)),在z=0的时候取值为0.5，并且 logi(z) 函数的取值范围为(0,1):

$$ logi(z) = 1/(1+e^{-z}) $$

当z>=0时，y>=0.5，分类为1；

当z<0时，y<0.5，分类为0；

其对应的 y 值我们可以视为类别1的概率预测值$P$.

一般的多元线性回归方程（任意阶可导的凸函数才能作为逻辑回归的目标函数）：

$$ z = w_0 + \textstyle\sum_{i=1}^n w_i x_i $$

将回归方程代入Logistic函数，得：

$$ P = P(y=1 | x, \theta) = 1/(1+e^{w_0 + \textstyle\sum_{i=1}^n w_i x_i}) $$

则，$ P(y=1 | x, \theta) = P, P(y=0 | x, \theta) = 1 - P $，
从中学习得出系数权值w，从而得到一个针对于当前数据的特征逻辑回归模型，
对于比较重视的特征，其对应的系数权值会更大些。

#### 逻辑回归的应用

1. 预测受伤患者的死亡率
2. 基于观察到的患者特征（年龄，性别，体重指数,各种血液检查的结果等）分析预测发生特定疾病（例如糖尿病，冠心病）的风险
3. 预测在给定的过程中，系统或产品的故障的可能性
4. 预测客户购买产品或中止订购的倾向
5. 预测一个人选择进入劳动力市场的可能性
6. 预测房主拖欠抵押贷款的可能性

#### 基于鸢尾花数据集的分类预测实战

代码链接：

### 学习问题与解答

1. 在多分类问题中，如何将多个二分类的逻辑回归进行组合以实现多分类

   答：多分类会得到多个方程，然后将学到的系数权值$w$代入方程中，查看概率值$P$

2. RDDs是Spark分发数据和计算的基础抽象类


### 学习思考与总结

通过此次得学习，我学到了逻辑回归的基本原理及其相关应用。逻辑回归有它的局限性，适合样本量较少的情况，而且精度不太高，但是用可解释性强。
因此，针对不同的项目，采用不同的方法很重要，若用神经网络处理鸢尾花数据集可能大材小用了，数据量大到一定程度，也许神经网络是个不错的选择。
