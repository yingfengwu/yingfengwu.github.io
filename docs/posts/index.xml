<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>所有文章 - yingfengwu</title>
        <link>https://yingfengwu.github.io/posts/</link>
        <description>所有文章 | yingfengwu</description>
        <generator>Hugo -- gohugo.io</generator><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Fri, 04 Jun 2021 17:57:40 &#43;0800</lastBuildDate><atom:link href="https://yingfengwu.github.io/posts/" rel="self" type="application/rss+xml" /><item>
    <title>win10上Tensorflow&#43;CUDA安装</title>
    <link>https://yingfengwu.github.io/win10%E4%B8%8Atensorflow-cuda%E5%AE%89%E8%A3%85/</link>
    <pubDate>Fri, 04 Jun 2021 17:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://yingfengwu.github.io/win10%E4%B8%8Atensorflow-cuda%E5%AE%89%E8%A3%85/</guid>
    <description><![CDATA[CUDA是一种由NVIDIA推出的通用并行计算架构，该架构使GPU能够解决复杂的计算问题。 包含了CUDA指令集架构（ISA）以及GPU内部的并行计算引擎。
CUDA安装 首先查看tensorflow官网 上测试过可行的相对应的版本:
然后，根据自己当前环境的要求，进入链接 选择相应的CUDA版本下载
安装到自己想要的路径下，然后一直下一步。
CUDA编译 下载好之后需要用Visual Studio软件将CUDA编译生成相应的可执行文件
tensorflow安装 用pip安装tensorflow指定版本
pip install tensorflow-gpu==1.15.4
tensorflow用GPU进行运算测试 代码如下：
1 2 3 4 5 6  import tensorflow as tf a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name=&#39;a&#39;) b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name=&#39;b&#39;) c = tf.matmul(a, b) sess = tf.Session(config=tf.ConfigProto(log_device_placement=True)) print sess.run(c)   本文简单总结，具体查看参考资料内容。
参考资料：
https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html https://blog.csdn.net/ccnucb/article/details/79873460]]></description>
</item><item>
    <title>基于LightGBM的分类预测学习笔记</title>
    <link>https://yingfengwu.github.io/%E5%9F%BA%E4%BA%8Elightgbm%E7%9A%84%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B/</link>
    <pubDate>Fri, 04 Jun 2021 17:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://yingfengwu.github.io/%E5%9F%BA%E4%BA%8Elightgbm%E7%9A%84%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B/</guid>
    <description><![CDATA[学习知识点概要   LightGBM的介绍及应用
  基于英雄联盟数据集的LightGBM分类实战
  学习内容 LightGBM的介绍 LightGBM是2017年由微软推出的可扩展机器学习系统，是微软旗下DMKT的一个开源项目，由2014年首届 阿里巴巴大数据竞赛获胜者之一柯国霖老师带领开发。它是一款基于GBDT（梯度提升决策树）算法的分 布式梯度提升框架，为了满足缩短模型计算时间的需求，LightGBM的设计思路主要集中在减小数据对内 存与计算性能的使用，以及减少多机器并行计算时的通讯代价。
LightGBM可以看作是XGBoost的升级豪华版，在获得与XGBoost近似精度的同时，又提供了更快的训练速 度与更少的内存消耗。正如其名字中的Light所蕴含的那样，LightGBM在大规模数据集上跑起来更加优 雅轻盈，一经推出便成为各种数据竞赛中刷榜夺冠的神兵利器。
 优点：  简单易用。提供了主流的Python\C++\R语言接口，用户可以轻松使用LightGBM建模并获得相当不错的效果。 高效可扩展。在处理大规模数据集时高效迅速、高准确度，对内存等硬件资源要求不高。 鲁棒性强。相较于深度学习模型不需要精细调参便能取得近似的效果。 LightGBM直接支持缺失值与类别特征，无需对数据额外进行特殊处理   缺点：  相对于深度学习模型无法对时空位置建模，不能很好地捕获图像、语音、文本等高维数据。 在拥有海量训练数据，并能找到合适的深度学习模型时，深度学习的精度可以遥遥领先LightGBM。    LightGBM原理:
LightGBM是基于CART树的集成模型，它的思想是串联多个决策树模型共同进行决策。基模型是CART回归 树，它有两个特点：（1）CART树，是一颗二叉树。（2）回归树，最后拟合结果是连续值。
那么如何串联呢？LightGBM采用迭代预测误差的方法串联。举个通俗的例子，我们现在需要预测一辆车 价值3000元。我们构建决策树1训练后预测为2600元，我们发现有400元的误差，那么决策树2的训练目 标为400元，但决策树2的预测结果为350元，还存在50元的误差就交给第三棵树……以此类推，每一颗树 用来估计之前所有树的误差，最后所有树预测结果的求和就是最终预测结果！
XGBoost模型可以表示为以下形式，我们约定$ f_t(x) $表示前 t 颗树的和，h_t(x)表示第 t 颗决策树，模型定义如下： $$ f_t(x)=\sum_{t=1}^T h_t(x) $$
由于模型递归生成，第t步的模型由第t-1步的模型形成，则可以写成： $$ f_t(x)=f_{t-1}(x)+h_t(x) $$
LightGBM底层实现了GBDT（Gradient Boosting Decision Tree）算法，并且添加了一系列的新特性：
 基于直方图算法进行优化，使数据存储更加方便、运算更快、鲁棒性强、模型更加稳定等。 提出了带深度限制的 Leaf-wise 算法，抛弃了大多数GBDT工具使用的按层生长 (level-wise) 的决策树生长策略，而使用了带有深度限制的按叶子生长策略，可以降低误差，得到更好的精度。 提出了单边梯度采样算法，排除大部分小梯度的样本，仅用剩下的样本计算信息增益，它是一种在减少数据量和保证精度上平衡的算法。 提出了互斥特征捆绑算法，高维度的数据往往是稀疏的，这种稀疏性启发我们设计一种无损的方法来 减少特征的维度。通常被捆绑的特征都是互斥的（即特征不会同时为非零值，像one-hot），这样两个特征捆绑起来就不会丢失信息。 直接支持类别特征(Categorical Feature)，即不需要进行one-hot编码 Cache命中率优化  LightGBM重要参数 基本参数调整  num_leaves参数 这是控制树模型复杂度的主要参数，一般的我们会使num_leaves小于（2的max_depth次方）， 以防止过拟合。由于LightGBM是leaf-wise建树与XGBoost的depth-wise建树方法不同，num_leaves比depth有更大的作用。 min_data_in_leaf 这是处理过拟合问题中一个非常重要的参数.]]></description>
</item><item>
    <title>基于XGBoost的分类预测学习笔记</title>
    <link>https://yingfengwu.github.io/%E5%9F%BA%E4%BA%8Exgboost%E7%9A%84%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B/</link>
    <pubDate>Wed, 02 Jun 2021 17:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://yingfengwu.github.io/%E5%9F%BA%E4%BA%8Exgboost%E7%9A%84%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B/</guid>
    <description><![CDATA[学习知识点概要   XGBoost的介绍及应用
  基于天气数据集的XGBoost分类实战
  学习内容 XGBoost的介绍 XGBoost是2016年由华盛顿大学陈天奇老师带领开发的一个可扩展机器学习系统，是一个可 供用户轻松解决分类、回归或排序问题的软件包。它内部实现了梯度提升树(GBDT)模型， 并对模型中的算法进行了诸多优化，在取得高精度的同时又保持了极快的速度。
更重要的是，XGBoost在系统优化和机器学习原理方面都进行了深入的考虑。毫不夸张的讲， XGBoost提供的可扩展性，可移植性与准确性推动了机器学习计算限制的上限，该系统在单台 机器上运行速度比当时流行解决方案快十倍以上，甚至在分布式系统中可以处理十亿级的数据。
 优点：  简单易用。相对其他机器学习库，用户可以轻松使用XGBoost并获得相当不错的效果。 高效可扩展。在处理大规模数据集时速度快效果好，对内存等硬件资源要求不高。 鲁棒性强。相对于深度学习模型不需要精细调参便能取得接近的效果。 XGBoost内部实现提升树模型，可以自动处理缺失值。   缺点：  相对于深度学习模型无法对时空位置建模，不能很好地捕获图像、语音、文本等高维数据。 在拥有海量训练数据，并能找到合适的深度学习模型时，深度学习的精度可以遥遥领先XGBoost。    XGBoost原理:
XGBoost是基于CART树的集成模型，它的思想是串联多个决策树模型共同进行决策。基模型是CART回归 树，它有两个特点：（1）CART树，是一颗二叉树。（2）回归树，最后拟合结果是连续值。
那么如何串联呢？XGBoost采用迭代预测误差的方法串联。举个通俗的例子，我们现在需要预测一辆车 价值3000元。我们构建决策树1训练后预测为2600元，我们发现有400元的误差，那么决策树2的训练目 标为400元，但决策树2的预测结果为350元，还存在50元的误差就交给第三棵树……以此类推，每一颗树 用来估计之前所有树的误差，最后所有树预测结果的求和就是最终预测结果！
XGBoost模型可以表示为以下形式，我们约定$ f_t(x) $表示前 t 颗树的和，h_t(x)表示第 t 颗决策树，模型定义如下： $$ f_t(x)=\sum_{t=1}^T h_t(x) $$
由于模型递归生成，第t步的模型由第t-1步的模型形成，则可以写成： $$ f_t(x)=f_{t-1}(x)+h_t(x) $$
XGBoost底层实现了GBDT（Gradient Boosting Decision Tree）算法，并对GBDT算法做了一系列优化：
 对目标函数进行了泰勒展示的二阶展开，可以更加高效拟合误差。 提出了一种估计分裂点的算法加速CART树的构建过程，同时可以处理稀疏数据。 提出了一种树的并行策略加速迭代。 为模型的分布式算法进行了底层优化  XGBoost重要参数    eta[默认0.3]    通过为每一颗树增加权重，提高模型的鲁棒性。]]></description>
</item><item>
    <title>动态规划总结（多示例&#43;讲解）</title>
    <link>https://yingfengwu.github.io/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%80%BB%E7%BB%93/</link>
    <pubDate>Tue, 01 Jun 2021 17:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://yingfengwu.github.io/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%80%BB%E7%BB%93/</guid>
    <description><![CDATA[动态规划功能强大，它能够解决子问题并使用这些答案来解决大问题。但 仅当每个子问题都是离散的，即不依赖于其他子问题时，动态规划才管用。 比如，想去以下地方旅游4天，假设将埃菲尔铁塔加入“背包”后，卢浮宫将 更“便宜”：只要1天时间，而不是1.5天。用动态规划对这种情况建模呢？ 这是没办法建模的，因为存在依赖关系。
   景点 停留天数 评分     埃菲尔铁塔 1.5天 8   卢浮宫 1.5天 9   巴黎圣母院 1.5天 7    一、斐波那契数列求解 题目:
写一个函数，输入 n ，求斐波那契（Fibonacci）数列的第 n 项（即 F(N)）。斐波那契数列的定义如下：
F(0) = 0, F(1) = 1
F(N) = F(N - 1) + F(N - 2), 其中 N &gt; 1.
斐波那契数列由 0 和 1 开始，之后的斐波那契数就是由之前的两数相加而得出。
😂
递归法   原理： 把f(n)问题的计算拆分成 f(n-1)和f(n−2)两个子问题的计算，并递归，以f(0)和f(1)为终止条件。]]></description>
</item><item>
    <title>基于逻辑回归的分类预测学习笔记</title>
    <link>https://yingfengwu.github.io/%E5%9F%BA%E4%BA%8E%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B/</link>
    <pubDate>Tue, 01 Jun 2021 17:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://yingfengwu.github.io/%E5%9F%BA%E4%BA%8E%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B/</guid>
    <description><![CDATA[学习知识点概要   逻辑回归的介绍及应用
  基于鸢尾花数据集的分类预测实战
  学习内容 逻辑回归的介绍 逻辑回归虽名为“回归”，但实际是一种分类学习方法。
 逻辑回归（或称对数几率回归）突出的特点：模型简单和模型可解释性强 优劣势：  优点：实现简单，易于理解和实现；计算代价不高，速度很快，存储资源低； 缺点：容易欠拟合，分类精度可能不高；由于其本质上是一个线性的分类器，所以不能应对较为复杂的数据情况   对于多分类（有三个及以上输出）而言，将多个二分类的逻辑回归组合，即可实现多分类  逻辑回归原理:
通过Logistic函数（或称为Sigmoid函数），对多元线性回归方程中的变量值进行决策（分类预测）。
sigmoid函数sigmoid
"sigmoid函数
Logistic函数(本文简写为logi(z)),在z=0的时候取值为0.5，并且 logi(z) 函数的取值范围为(0,1):
$$ logi(z) = 1/(1+e^{-z}) $$
当z&gt;=0时，y&gt;=0.5，分类为1；
当z&lt;0时，y&lt;0.5，分类为0；
其对应的 y 值我们可以视为类别1的概率预测值$P$.
一般的多元线性回归方程（任意阶可导的凸函数才能作为逻辑回归的目标函数）：
$$ z = w_0 + \textstyle\sum_{i=1}^n w_i x_i $$
将回归方程代入Logistic函数，得：
$$ P = P(y=1 | x, \theta) = 1/(1+e^{w_0 + \textstyle\sum_{i=1}^n w_i x_i}) $$
则，$ P(y=1 | x, \theta) = P, P(y=0 | x, \theta) = 1 - P $， 从中学习得出系数权值w，从而得到一个针对于当前数据的特征逻辑回归模型， 对于比较重视的特征，其对应的系数权值会更大些。]]></description>
</item><item>
    <title>排序算法总结（多示例&#43;讲解）</title>
    <link>https://yingfengwu.github.io/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/</link>
    <pubDate>Tue, 01 Jun 2021 17:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://yingfengwu.github.io/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/</guid>
    <description><![CDATA[动态规划功能强大，它能够解决子问题并使用这些答案来解决大问题。但 仅当每个子问题都是离散的，即不依赖于其他子问题时，动态规划才管用。 比如，想去以下地方旅游4天，假设将埃菲尔铁塔加入“背包”后，卢浮宫将 更“便宜”：只要1天时间，而不是1.5天。用动态规划对这种情况建模呢？ 这是没办法建模的，因为存在依赖关系。
一、冒泡排序 1 2 3 4 5 6  def bubble_sort(arr): for i in range(0, len(arr)): # 对每个元素 for j in range(1, len(arr)-i): # 最大的往上冒，冒完需要减1避免再次计算该值 if arr[j] &gt; arr[j+1]: # 此处，&#34;&gt;&#34;为大的数往上冒，&#34;&lt;&#34;为小的数往上冒 arr[j], arr[j+1] = arr[j+1], arr[j] # 交换位置 return a   二、选择排序 1 2 3 4 5 6 7 8 9  def selection_sort(arr): for i in range(len(arr)-1): # 减1是为了第2个for的起始i+1 min_index = i for j in range(i+1, len(arr)): # 遍历后面的值，并记录最小值的索引 if arr[min_index] &gt; arr[j]: # 要是取最大值的索引，则改&#34;&gt;&#34;为&#34;&lt;&#34; min_index = j if i !]]></description>
</item><item>
    <title>Matplotlib画各种图的总结</title>
    <link>https://yingfengwu.github.io/matplotlib/</link>
    <pubDate>Mon, 31 May 2021 17:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://yingfengwu.github.io/matplotlib/</guid>
    <description><![CDATA[数据可视化的图表种类繁多，各式各样，因此我们需要掌握如何在特定场景下使用特定的图表。 数据可视化是为业务目的服务的，好的可视化图表可以起到清晰准确反映业务结果的目的，在选 择使用何种图表时，通常我们需要首先考虑你想通过可视化阐述什么样的故事，受众是谁，以及打算如何分析结果。
关于如何利用数据创造出吸引人的、信息量大的、有说服力的故事，进而达到有效沟通的目的， 可以进一步阅读这本书《用数据讲故事》学习。
学习知识点概要 常见的场景分为5大类：
1）展示趋势变化（Evolution）
2）展示分布关系（Distribution）
3）展示相关关系（Correlation）
4）展示排序信息（Ranking）
5）展示组成关系（Part of a whole）
学习内容 展示趋势变化的图 1.折线图（Line chart） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  import matplotlib.pyplot as plt import numpy as np import pandas as pd # 创建数据，分别对应X轴和Y轴，注意X轴要是有序排列的 df1=pd.DataFrame({&#39;x1data&#39;: range(1,101), &#39;y1data&#39;: np.]]></description>
</item><item>
    <title>Spark</title>
    <link>https://yingfengwu.github.io/spark/</link>
    <pubDate>Mon, 31 May 2021 17:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://yingfengwu.github.io/spark/</guid>
    <description><![CDATA[Spark是专为大规模数据处理而设计的快速通用的计算引擎。 诞生于2009年，是加州大学伯克利分校RAD实验室的一个研究项目，最初基于Hadoop Mapreduce。 但是，由于Mapreduce在迭代式计算和交互式上低效，因此引入内存存储。
Spark包括多个紧密集成的组件：
 name: &ldquo;featured-image&rdquo; src: &ldquo;featured-image.png&rdquo;  Spark的组件 Spark core  基本功能：任务调度，内存管理，容错机制 内部定义了RDDs（Resilient distributed datasets, 弹性分布式数据集） 提供API创建和操作RDDs 在应用场景中，为其他组件提供底层的服务  Spark SQL  Spark处理结构化数据的库，类似Hive SQL，Mysql 应用场景，企业用来做报表统计  Spark Streaming  实时数据流处理组件，类似storm 提供API操作实时流数据 应用场景，企业用来从Kafka（等消息队列中）接收数据做实时统计  Mlib  一个包含通用机器学习功能的包，Machine learning lib，包括分类、聚类、回归、模型评估和数据导入等 Mlib提供的方法都支持集群上的横向扩展（平时使用python是单机处理且有限的，而Mlib是集群的） 应用场景，机器学习  Graphx  处理图的库（如社交网络图），并进行图的并行计算 像Spark Steaming和Spark SQL一样，它也继承了RDDs API 提供了各种图操作和常用的图算法，例如PangeRank算法 应用场景，图计算  Cluster Managers  集群管理，Spark自带的一个集群管理是单独调度器 常见集群管理包括Hadoop YARN，Apache Mesos  紧密集成的优点  Spark底层优化了，基于Spark底层的组件也得到了相应的优化 紧密集成，节省了各个组件组合使用时的部署，测试等时间 向Spark增加新的组件时，其它组件可立刻享用新组件的功能  Spark与Hadoop比较  Spark应用场景：时效性要求高（因为基于内存）、机器学习领域 Spark不具有HDFS（分布式文件系统）的存储能力，要借助HDFS等工具来持久化数据 Hadoop应用场景：离线处理、对时效性要求不高  安装 Spark安装 1.]]></description>
</item><item>
    <title>提升树模型</title>
    <link>https://yingfengwu.github.io/%E6%8F%90%E5%8D%87%E6%A0%91/</link>
    <pubDate>Mon, 31 May 2021 17:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://yingfengwu.github.io/%E6%8F%90%E5%8D%87%E6%A0%91/</guid>
    <description><![CDATA[回归问题的提升树方法 算法1：
输入：训练数据集$ T={(x_1,y_1),(x_2,y_2),&hellip;,(x_N,y_N)}, x_i \in X \subseteq R^n, y_i \in Y \subseteq R $
输出：提升树$ f_m(x) $
(1) 初始化$ f_0(x)=0 $
(2) 对$ m=1,2,&hellip;,M $
(2.1) 按式(1)计算残差$ r_{mi}=y_i-f_{m-1}(x_i) $
(2.2) 拟合残差$r_{mi}$学习一个回归树，得到$T(x;\Theta_m)$
(2.3) 更新$ f_m(x)=f_{m-1}(x)+T(x;\Theta_m) $
(3) 得到回归问题的提升树$ f_M(x)=\displaystyle\sum_{m=1}^M T(x;\Theta_m) $
例子：
                 $x_i$ 1 2 3 4 5 6 7 8 9   $y_i$ 5.]]></description>
</item><item>
    <title>python数据结构栈和队列的相关方法</title>
    <link>https://yingfengwu.github.io/python%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%93%8D%E4%BD%9C/</link>
    <pubDate>Fri, 28 May 2021 17:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://yingfengwu.github.io/python%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%93%8D%E4%BD%9C/</guid>
    <description><![CDATA[s = stack()
stack()函数方法如下：
   栈操作 栈内容 返回值     s.is_empty() [] True   s.push(4) [4]    s.push(‘dog’) [4,’dog’]    s.peek() [4,’dog’] ‘dog’   s.push(True) [4,’dog’,True]    s.size() [4,’dog’,True] 3   s.is_empty() [4,’dog’,True] False   s.push(8.4) [4,’dog’,True,8.4]    s.pop() [4,’dog’,True] 8.4   s.pop() [4,’dog’] True   s.size() [4,’dog’] 2    q = Queue()]]></description>
</item></channel>
</rss>
