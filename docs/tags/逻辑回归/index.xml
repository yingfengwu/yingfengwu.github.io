<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>逻辑回归 - 标签 - yingfengwu</title>
        <link>https://yingfengwu.github.io/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</link>
        <description>逻辑回归 - 标签 - yingfengwu</description>
        <generator>Hugo -- gohugo.io</generator><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Tue, 01 Jun 2021 17:57:40 &#43;0800</lastBuildDate><atom:link href="https://yingfengwu.github.io/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/" rel="self" type="application/rss+xml" /><item>
    <title>基于逻辑回归的分类预测学习笔记</title>
    <link>https://yingfengwu.github.io/%E5%9F%BA%E4%BA%8E%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B/</link>
    <pubDate>Tue, 01 Jun 2021 17:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://yingfengwu.github.io/%E5%9F%BA%E4%BA%8E%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B/</guid>
    <description><![CDATA[学习知识点概要   逻辑回归的介绍及应用
  基于鸢尾花数据集的分类预测实战
  学习内容 逻辑回归的介绍 逻辑回归虽名为“回归”，但实际是一种分类学习方法。
 逻辑回归（或称对数几率回归）突出的特点：模型简单和模型可解释性强 优劣势：  优点：实现简单，易于理解和实现；计算代价不高，速度很快，存储资源低； 缺点：容易欠拟合，分类精度可能不高；由于其本质上是一个线性的分类器，所以不能应对较为复杂的数据情况   对于多分类（有三个及以上输出）而言，将多个二分类的逻辑回归组合，即可实现多分类  逻辑回归原理:
通过Logistic函数（或称为Sigmoid函数），对多元线性回归方程中的变量值进行决策（分类预测）。
sigmoid函数sigmoid
"sigmoid函数
Logistic函数(本文简写为logi(z)),在z=0的时候取值为0.5，并且 logi(z) 函数的取值范围为(0,1):
$$ logi(z) = 1/(1+e^{-z}) $$
当z&gt;=0时，y&gt;=0.5，分类为1；
当z&lt;0时，y&lt;0.5，分类为0；
其对应的 y 值我们可以视为类别1的概率预测值$P$.
一般的多元线性回归方程（任意阶可导的凸函数才能作为逻辑回归的目标函数）：
$$ z = w_0 + \textstyle\sum_{i=1}^n w_i x_i $$
将回归方程代入Logistic函数，得：
$$ P = P(y=1 | x, \theta) = 1/(1+e^{w_0 + \textstyle\sum_{i=1}^n w_i x_i}) $$
则，$ P(y=1 | x, \theta) = P, P(y=0 | x, \theta) = 1 - P $， 从中学习得出系数权值w，从而得到一个针对于当前数据的特征逻辑回归模型， 对于比较重视的特征，其对应的系数权值会更大些。]]></description>
</item></channel>
</rss>
